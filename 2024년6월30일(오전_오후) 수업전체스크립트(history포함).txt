t/web-server-pod, cannot delete Pods with local storage (use --delete-emptydir-data to override): default/weblog, cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kube-proxy-7wbj6, kube-system/weave-net-7pmpm], continuing command...
There are pending nodes to be drained:
 k8s-worker2
cannot delete Pods declare no controller (use --force to override): default/campus-01, default/fluentd, default/web-server-pod
cannot delete Pods with local storage (use --delete-emptydir-data to override): default/weblog
cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kube-proxy-7wbj6, kube-system/weave-net-7pmpm
ubuntu@console:~$ kubectl drain k8s-worker2 --ignore-daemonsets
node/k8s-worker2 already cordoned
error: unable to drain node "k8s-worker2" due to error:[cannot delete Pods declare no controller (use --force to override): default/campus-01, default/fluentd, default/web-server-pod, cannot delete Pods with local storage (use --delete-emptydir-data to override): default/weblog], continuing command...
There are pending nodes to be drained:
 k8s-worker2
cannot delete Pods declare no controller (use --force to override): default/campus-01, default/fluentd, default/web-server-pod
cannot delete Pods with local storage (use --delete-emptydir-data to override): default/weblog
ubuntu@console:~$ kubectl drain k8s-worker2 --ignore-daemonsets --force
node/k8s-worker2 already cordoned
error: unable to drain node "k8s-worker2" due to error:cannot delete Pods with local storage (use --delete-emptydir-data to override): default/weblog, continuing command...
There are pending nodes to be drained:
 k8s-worker2
cannot delete Pods with local storage (use --delete-emptydir-data to override): default/weblog
ubuntu@console:~$ kubectl drain k8s-worker2 --ignore-daemonsets --force --delete-emptydir-data
node/k8s-worker2 already cordoned
Warning: deleting Pods that declare no controller: default/campus-01, default/fluentd, default/web-server-pod, default/weblog; ignoring DaemonSet-managed Pods: kube-system/kube-proxy-7wbj6, kube-system/weave-net-7pmpm
evicting pod devops/eshop-order-678978ccc5-z575n
evicting pod default/nginx-app-f77bb967-v4qb5
evicting pod default/campus-01
evicting pod default/fluentd
evicting pod default/nginx-app-f77bb967-tj6g4
evicting pod default/weblog
evicting pod default/web-server-pod
evicting pod devops/eshop-order-678978ccc5-2s9vq
evicting pod devops/eshop-order-678978ccc5-rwst4
I0630 15:24:12.373931    2681 request.go:697] Waited for 1.039761621s due to client-side throttling, not priority and fairness, request: GET:https://10.0.2.10:6443/api/v1/namespaces/default/pods/fluentd
pod/eshop-order-678978ccc5-z575n evicted
pod/eshop-order-678978ccc5-rwst4 evicted
pod/nginx-app-f77bb967-tj6g4 evicted
pod/web-server-pod evicted
pod/eshop-order-678978ccc5-2s9vq evicted
pod/nginx-app-f77bb967-v4qb5 evicted
pod/fluentd evicted
pod/campus-01 evicted
pod/weblog evicted
node/k8s-worker2 drained
ubuntu@console:~$ clear
ubuntu@console:~$ kubectl get nodes
NAME          STATUS                     ROLES           AGE    VERSION
k8s-master    Ready                      control-plane   126d   v1.28.0
k8s-worker1   Ready                      <none>          126d   v1.28.0
k8s-worker2   Ready,SchedulingDisabled   <none>          126d   v1.28.0
ubuntu@console:~$ kubectl get pods -A
NAMESPACE       NAME                                        READY   STATUS    RESTARTS         AGE
default         fast-01                                     1/1     Running   0                3h1m
default         front-end-7f8c6f6f69-vqdf9                  1/1     Running   0                5h43m
default         front-end-7f8c6f6f69-xplfj                  1/1     Running   0                5h43m
default         nginx-app-f77bb967-g5jm4                    1/1     Running   0                103s
default         nginx-app-f77bb967-rkz85                    1/1     Running   0                103s
default         nginx-app-f77bb967-s9qgv                    1/1     Running   0                71m
devops          eshop-order-678978ccc5-45b7b                1/1     Running   0                5h43m
devops          eshop-order-678978ccc5-kkkxz                1/1     Running   0                5h43m
devops          eshop-order-678978ccc5-m2699                1/1     Running   0                103s
devops          eshop-order-678978ccc5-z6lxc                1/1     Running   0                103s
devops          eshop-order-678978ccc5-zkmql                1/1     Running   0                103s
ingress-nginx   appjs-57849f65b7-26vh6                      1/1     Running   0                5h43m
ingress-nginx   appjs-57849f65b7-2mk6j                      1/1     Running   0                5h43m
ingress-nginx   appjs-57849f65b7-hz57q                      1/1     Running   0                5h43m
ingress-nginx   ingress-nginx-controller-68c95587bf-5bptr   1/1     Running   0                5h43m
ingress-nginx   nginx-5b585d57d4-5zn8s                      1/1     Running   0                5h43m
kube-system     coredns-5dd5756b68-9fx7l                    1/1     Running   8 (5h50m ago)    126d
kube-system     coredns-5dd5756b68-jkm52                    1/1     Running   8 (5h50m ago)    126d
kube-system     etcd-k8s-master                             1/1     Running   8 (5h50m ago)    126d
kube-system     kube-apiserver-k8s-master                   1/1     Running   8 (5h50m ago)    126d
kube-system     kube-controller-manager-k8s-master          1/1     Running   8 (5h50m ago)    126d
kube-system     kube-proxy-5slnn                            1/1     Running   8 (5h2m ago)     126d
kube-system     kube-proxy-7wbj6                            1/1     Running   8 (4h57m ago)    126d
kube-system     kube-proxy-kt4j4                            1/1     Running   8 (5h50m ago)    126d
kube-system     kube-scheduler-k8s-master                   1/1     Running   8 (5h50m ago)    126d
kube-system     metrics-server-5dcdc6fffb-8m7j7             1/1     Running   0                5h43m
kube-system     weave-net-7pmpm                             2/2     Running   16 (4h57m ago)   126d
kube-system     weave-net-8wv5c                             2/2     Running   18 (5h50m ago)   126d
kube-system     weave-net-pldfd                             2/2     Running   17 (5h2m ago)    126d
ubuntu@console:~$ kubectl get pods -o wide -A
NAMESPACE       NAME                                        READY   STATUS    RESTARTS         AGE     IP           NODE          NOMINATED NODE   READINESS GATES
default         fast-01                                     1/1     Running   0                3h1m    10.44.0.11   k8s-worker1   <none>           <none>
default         front-end-7f8c6f6f69-vqdf9                  1/1     Running   0                5h43m   10.44.0.1    k8s-worker1   <none>           <none>
default         front-end-7f8c6f6f69-xplfj                  1/1     Running   0                5h43m   10.44.0.7    k8s-worker1   <none>           <none>
default         nginx-app-f77bb967-g5jm4                    1/1     Running   0                108s    10.44.0.15   k8s-worker1   <none>           <none>
default         nginx-app-f77bb967-rkz85                    1/1     Running   0                108s    10.44.0.14   k8s-worker1   <none>           <none>
default         nginx-app-f77bb967-s9qgv                    1/1     Running   0                71m     10.44.0.13   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-45b7b                1/1     Running   0                5h43m   10.44.0.3    k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-kkkxz                1/1     Running   0                5h43m   10.44.0.10   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-m2699                1/1     Running   0                108s    10.44.0.12   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-z6lxc                1/1     Running   0                108s    10.44.0.17   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-zkmql                1/1     Running   0                108s    10.44.0.16   k8s-worker1   <none>           <none>
ingress-nginx   appjs-57849f65b7-26vh6                      1/1     Running   0                5h43m   10.44.0.6    k8s-worker1   <none>           <none>
ingress-nginx   appjs-57849f65b7-2mk6j                      1/1     Running   0                5h43m   10.44.0.4    k8s-worker1   <none>           <none>
ingress-nginx   appjs-57849f65b7-hz57q                      1/1     Running   0                5h43m   10.44.0.8    k8s-worker1   <none>           <none>
ingress-nginx   ingress-nginx-controller-68c95587bf-5bptr   1/1     Running   0                5h43m   10.44.0.9    k8s-worker1   <none>           <none>
ingress-nginx   nginx-5b585d57d4-5zn8s                      1/1     Running   0                5h43m   10.44.0.2    k8s-worker1   <none>           <none>
kube-system     coredns-5dd5756b68-9fx7l                    1/1     Running   8 (5h50m ago)    126d    10.32.0.3    k8s-master    <none>           <none>
kube-system     coredns-5dd5756b68-jkm52                    1/1     Running   8 (5h50m ago)    126d    10.32.0.2    k8s-master    <none>           <none>
kube-system     etcd-k8s-master                             1/1     Running   8 (5h50m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-apiserver-k8s-master                   1/1     Running   8 (5h50m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-controller-manager-k8s-master          1/1     Running   8 (5h50m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-proxy-5slnn                            1/1     Running   8 (5h2m ago)     126d    10.0.2.11    k8s-worker1   <none>           <none>
kube-system     kube-proxy-7wbj6                            1/1     Running   8 (4h57m ago)    126d    10.0.2.12    k8s-worker2   <none>           <none>
kube-system     kube-proxy-kt4j4                            1/1     Running   8 (5h50m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-scheduler-k8s-master                   1/1     Running   8 (5h50m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     metrics-server-5dcdc6fffb-8m7j7             1/1     Running   0                5h43m   10.44.0.5    k8s-worker1   <none>           <none>
kube-system     weave-net-7pmpm                             2/2     Running   16 (4h57m ago)   126d    10.0.2.12    k8s-worker2   <none>           <none>
kube-system     weave-net-8wv5c                             2/2     Running   18 (5h50m ago)   126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     weave-net-pldfd                             2/2     Running   17 (5h2m ago)    126d    10.0.2.11    k8s-worker1   <none>           <none>
ubuntu@console:~$ kubectl get nodes
NAME          STATUS                     ROLES           AGE    VERSION
k8s-master    Ready                      control-plane   126d   v1.28.0
k8s-worker1   Ready                      <none>          126d   v1.28.0
k8s-worker2   Ready,SchedulingDisabled   <none>          126d   v1.28.0
ubuntu@console:~$ kubectl uncordon k8s-worker2
node/k8s-worker2 uncordoned
ubuntu@console:~$ kubectl get nodes
NAME          STATUS   ROLES           AGE    VERSION
k8s-master    Ready    control-plane   126d   v1.28.0
k8s-worker1   Ready    <none>          126d   v1.28.0
k8s-worker2   Ready    <none>          126d   v1.28.0
ubuntu@console:~$ kubectl get pods -o wide -A
NAMESPACE       NAME                                        READY   STATUS    RESTARTS         AGE     IP           NODE          NOMINATED NODE   READINESS GATES
default         fast-01                                     1/1     Running   0                3h6m    10.44.0.11   k8s-worker1   <none>           <none>
default         front-end-7f8c6f6f69-vqdf9                  1/1     Running   0                5h48m   10.44.0.1    k8s-worker1   <none>           <none>
default         front-end-7f8c6f6f69-xplfj                  1/1     Running   0                5h48m   10.44.0.7    k8s-worker1   <none>           <none>
default         nginx-app-f77bb967-g5jm4                    1/1     Running   0                6m31s   10.44.0.15   k8s-worker1   <none>           <none>
default         nginx-app-f77bb967-rkz85                    1/1     Running   0                6m31s   10.44.0.14   k8s-worker1   <none>           <none>
default         nginx-app-f77bb967-s9qgv                    1/1     Running   0                75m     10.44.0.13   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-45b7b                1/1     Running   0                5h48m   10.44.0.3    k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-kkkxz                1/1     Running   0                5h48m   10.44.0.10   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-m2699                1/1     Running   0                6m31s   10.44.0.12   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-z6lxc                1/1     Running   0                6m31s   10.44.0.17   k8s-worker1   <none>           <none>
devops          eshop-order-678978ccc5-zkmql                1/1     Running   0                6m31s   10.44.0.16   k8s-worker1   <none>           <none>
ingress-nginx   appjs-57849f65b7-26vh6                      1/1     Running   0                5h48m   10.44.0.6    k8s-worker1   <none>           <none>
ingress-nginx   appjs-57849f65b7-2mk6j                      1/1     Running   0                5h48m   10.44.0.4    k8s-worker1   <none>           <none>
ingress-nginx   appjs-57849f65b7-hz57q                      1/1     Running   0                5h48m   10.44.0.8    k8s-worker1   <none>           <none>
ingress-nginx   ingress-nginx-controller-68c95587bf-5bptr   1/1     Running   0                5h48m   10.44.0.9    k8s-worker1   <none>           <none>
ingress-nginx   nginx-5b585d57d4-5zn8s                      1/1     Running   0                5h48m   10.44.0.2    k8s-worker1   <none>           <none>
kube-system     coredns-5dd5756b68-9fx7l                    1/1     Running   8 (5h55m ago)    126d    10.32.0.3    k8s-master    <none>           <none>
kube-system     coredns-5dd5756b68-jkm52                    1/1     Running   8 (5h55m ago)    126d    10.32.0.2    k8s-master    <none>           <none>
kube-system     etcd-k8s-master                             1/1     Running   8 (5h55m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-apiserver-k8s-master                   1/1     Running   8 (5h55m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-controller-manager-k8s-master          1/1     Running   8 (5h55m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-proxy-5slnn                            1/1     Running   8 (5h7m ago)     126d    10.0.2.11    k8s-worker1   <none>           <none>
kube-system     kube-proxy-7wbj6                            1/1     Running   8 (5h2m ago)     126d    10.0.2.12    k8s-worker2   <none>           <none>
kube-system     kube-proxy-kt4j4                            1/1     Running   8 (5h55m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     kube-scheduler-k8s-master                   1/1     Running   8 (5h55m ago)    126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     metrics-server-5dcdc6fffb-8m7j7             1/1     Running   0                5h48m   10.44.0.5    k8s-worker1   <none>           <none>
kube-system     weave-net-7pmpm                             2/2     Running   16 (5h2m ago)    126d    10.0.2.12    k8s-worker2   <none>           <none>
kube-system     weave-net-8wv5c                             2/2     Running   18 (5h55m ago)   126d    10.0.2.10    k8s-master    <none>           <none>
kube-system     weave-net-pldfd                             2/2     Running   17 (5h7m ago)    126d    10.0.2.11    k8s-worker1   <none>           <none>
ubuntu@console:~$ history
    1  sudo -i
    2  sudo -i
    3  nmcli dev status
    4  sudo -i
    5  hostname
    6  history 
    7  sudo -i
    8  etcdctl version
    9  ls
   10  vi /etc/hosts
   11  sudo vi /etc/hosts
   12  hostname
   13  date
   14  localectl --help
   15  localectl status
   16  localectl list-locales | grep -i kr
   17  localectl list-locales
   18  locale
   19  sudo apt install language-pack-ko
   20  sudo vi /etc/default/locale
   21  sudo localectl set-locale LANG=ko_KR.utf8
   22  sudo vi /etc/default/locale
   23  localectl status
   24  date
   25  cat /etc/default/locale
   26  sudo timedatectl --help
   27  sudo timedatectl status
   28  date
   29  sudo timedatectl status
   30  sudo timedatectl set-timezone 'Asia/Seoul'
   31  date
   32  cal
   33  nmtui
   34  date
   35  exit
   36  sudo localectl set-locale LANG=C.UTF-8
   37  locale
   38  cat /etc/default/locale 
   39  sudo reboot
   40  sudo -i
   41  exit
   42  source <(kubectl completion bash)
   43  echo "source <(kubectl completion bash)" >> ~/.bashrc
   44  sudo -i
   45  ssh-keygen -t rsa
   46  ssh-copy-id k8s-master
   47  ssh-copy-id hk8s-master
   48  ssh-copy-id k8s-worker1
   49  ssh-copy-id hk8s-worker1
   50  ssh-copy-id hk8s-worker2
   51  ssh-copy-id hk8s-master
   52  ssh-copy-id k8s-master
   53  ssh-copy-id k8s-worker1
   54  ssh-copy-id k8s-worker2
   55  ssh-copy-id k8s-worker1
   56  ssh-copy-id k8s-worker2
   57  ls
   58  cat .ssh/known_hosts
   59  ssh k8s-master
   60  ssh hk8s-master
   61  ssh k8s-worker1
   62  ssh k8s-worker2
   63  ssh hk8s-worker1
   64  ssh hk8s-worker2
   65  ssh-copy-id root@k8s-master
   66  ssh-copy-id root@hk8s-master
   67  mkdir .kube
   68  cd .kube
   69  scp root@k8s-master:/etc/kubernetes/admin.conf ~/.kube/config1
   70  scp root@hk8s-master:/etc/kubernetes/admin.conf ~/.kube/config2
   71  vi config1
   72  kubectl --kubeconfig=config1 config use-context k8s
   73  kubectl --kubeconfig=config1 config current-context
   74  kubectl --kubeconfig=config1 get nodes
   75  kubectl --kubeconfig=config2 get nodes
   76  sudo snap install yq
   77  cat config2 | yq e '.clusters[0].cluster.certificate-authority-data' - | base64 -d > hca.crt
   78  cat config2 | yq e '.users[0].user.client-certificate-data' - | base64 -d > hadmin.pub
   79  cat config2 | yq e '.users[0].user.client-key-data' - | base64 -d > hadmin.key
   80  kubectl config --embed-certs=true --kubeconfig=config1 set-cluster hk8s-cluster --server=https://10.0.2.20:6443 --certificate-authority=./hca.crt  
   81  kubectl config --embed-certs=true --kubeconfig=config1 set-credentials hk8s-admin --client-certificate=./hadmin.pub --client-key=./hadmin.key
   82  kubectl config --kubeconfig=config1 set-context hk8s --cluster=hk8s-cluster --user=hk8s-admin
   83  kubectl --kubeconfig=config1 config get-contexts
   84  kubectl --kubeconfig=config1 get node
   85  kubectl --kubeconfig=config1 config use-context hk8s
   86  kubectl --kubeconfig=config1 get node
   87  cp config1 ~/.kube/config
   88  cd
   89  kubectl config get-contexts
   90  kubectl config use-context k8s
   91  kubectl get nodes 
   92  kubectl config use-context hk8s
   93  kubectl get nodes 
   94  sudo -i
   95  kubectl get nodes
   96  kubectl config current-context 
   97  kubectl config use-context k8s
   98  kubectl get nodes
   99  exit
  100  kubectl get nodes
  101  sudo init 0
  102  kubectl get deployments,pod,svc -A
  103  kubectl get deployments,pod,svc 
  104  kubectl get pod -A
  105  kubectl get deployments.apps -A
  106  kubectl get svc -A
  107  kubectl get pod -A
  108  kubectl config use-context hk8s
  109  cat <<EOF | kubectl apply -f -
  110  ---
  111  ## namespcae customera
  112  apiVersion: v1
  113  kind: Namespace
  114  metadata:
  115    name: customera
  116    labels:
  117      partition: customera
  118  ---
  119  ## namespcae customera
  120  apiVersion: v1
  121  kind: Namespace
  122  metadata:
  123    name: customerb
  124    labels:
  125      partition: customerb
  126  ---
  127  apiVersion: v1
  128  kind: Namespace
  129  metadata:
  130    name: migops
  131    labels:
  132      team: migops
  133  ---
  134  apiVersion: v1
  135  kind: Namespace
  136  metadata:
  137    name: devops
  138    labels:
  139      team: devops
  140  ---
  141  apiVersion: v1
  142  kind: Namespace
  143  metadata:
  144    name: presales
  145    labels:
  146      team: presales
  147  ---
  148  # NetworkPolicy
  149  kind: Pod
  150  apiVersion: v1
  151  metadata:
  152    name: web
  153    namespace: migops
  154    labels:
  155      app: webwas
  156      tier: frontend
  157  spec:
  158    containers:
  159    - name: web
  160      image: smlinux/cent-mysql:v1
  161      command: ["/bin/bash"]
  162      args: ["-c", "while true; do echo hello; sleep 10;done"]
  163  ---
  164  kind: Pod
  165  apiVersion: v1
  166  metadata:
  167    name: was
  168    namespace: migops
  169    labels:
  170      app: webwas
  171      tier: application
  172  spec:
  173    containers:
  174    - name: was
  175      image: smlinux/cent-mysql:v1
  176      command: ["/bin/bash"]
  177      args: ["-c", "while true; do echo hello; sleep 10;done"]
  178  ---
  179  kind: Pod
  180  apiVersion: v1
  181  metadata:
  182    name: db
  183    namespace: migops
  184    labels:
  185      app: webwas
  186      tier: database
  187  spec:
  188    containers:
  189      - name: db
  190        image: mysql:5.7
  191        env:
  192        - name: MYSQL_ROOT_PASSWORD
  193          value: pass
  194  ---
  195  ## init container
  196  apiVersion: v1
  197  kind: Pod
  198  metadata:
  199    name: web
  200  spec:
  201    containers:
  202    - name: nginx
  203      image: nginx
  204      command: ['sh', '-c', 'if [ ! -e "/opt/test" ];then exit;fi;']
  205      volumeMounts:
  206      - name: workdir
  207        mountPath: /opt
  208    volumes:
  209    - name: workdir
  210      emptyDir: {}
  211  ---
  212  ## log exam
  213  apiVersion: v1
  214  kind: Pod
  215  metadata:
  216    name: custom-app
  217    namespace: default
  218  spec:
  219    containers:
  220    - name: app
  221      image: busybox
  222      command: ['/bin/sh', '-c', 'while :;do echo -e "find files\nerror: file not found\nToday: $(date)\nHostname: $(hostname)"; sleep 60; done']
  223  ---
  224  ## sidecar exam
  225  apiVersion: v1
  226  kind: Pod
  227  metadata:
  228    name: cka-webserver
  229    namespace: default
  230  spec:
  231    containers:
  232    - image: nginx:1.14
  233      name: webserver
  234      volumeMounts:
  235      - mountPath: /var/log/nginx
  236        name: log
  237    volumes:
  238    - name: log
  239      emptyDir: {}
  240  ---
  241  ## cpu load :
  242  apiVersion: v1
  243  kind: Pod
  244  metadata:
  245    labels:
  246      name: overloaded-cpu
  247    name: campus-01
  248  spec:
  249    containers:
  250    - name: campus
  251      image: smlinux/vish-stress
  252      resources:
  253        limits:
  254          cpu: "0.4"
  255          memory: "300Mi"
  256        requests:
  257          cpu: "0.4"
  258          memory: "250Mi"
  259      args:
  260      - -cpus
  261      - "1"
  262      - -mem-total
  263      - "150Mi"
  264      - -mem-alloc-size
  265      - "100Mi"
  266      - -mem-alloc-sleep
  267      - "1s"
  268  ---
  269  apiVersion: v1
  270  kind: Pod
  271  metadata:
  272    labels:
  273      name: overloaded-cpu
  274    name: fast-01
  275  spec:
  276    containers:
  277    - name: fast
  278      image: smlinux/vish-stress
  279      resources:
  280        limits:
  281          cpu: "0.2"
  282          memory: "300Mi"
  283        requests:
  284          cpu: "0.2"
  285          memory: "250Mi"
  286      args:
  287      - -cpus
  288      - "1"
  289      - -mem-total
  290      - "250Mi"
  291      - -mem-alloc-size
  292      - "100Mi"
  293      - -mem-alloc-sleep
  294      - "1s"
  295  ---
  296  #multi-container
  297  apiVersion: v1
  298  kind: Pod
  299  metadata:
  300    name: busybox-sleep
  301  spec:
  302    containers:
  303    - name: busybox
  304      image: busybox
  305      command: ["/bin/sh"]
  306      args: ["-c", "while true; do sleep 1000; done"]
  307  ---
  308  EOF
  309  kubectl get nodes
  310  kubectl get deployments.apps -A
  311  kubectl get pod -A
  312  kubectl get svc -A
  313  kubectl get deployments.apps -A
  314  kubectl get pod -A
  315  kubectl config use-context k8s
  316  kubectl get pv 
  317  cat <<EOF | kubectl apply -f -
  318  apiVersion: v1
  319  kind: PersistentVolume
  320  metadata:
  321    name: pv3
  322  spec:
  323    capacity:
  324      storage: 1Gi
  325    accessModes:
  326    - ReadWriteOnce
  327    persistentVolumeReclaimPolicy: Recycle
  328    storageClassName: csi-hostpath-sc
  329    hostPath:
  330      path: /data/pv1
  331  ---
  332  EOF
  333  kubectl get pv 
  334  kubectl config use-context hk8s
  335  kubectl get pod -n customera 
  336  kubectl config use-context hk8s
  337  cat <<EOF | kubectl apply -f -
  338  apiVersion: v1
  339  kind: Pod
  340  metadata:
  341    name: custom-app
  342    namespace: customera
  343  spec:
  344    containers:
  345    - name: app
  346      image: busybox
  347      command: ['/bin/sh', '-c', 'while :;do echo -e "find files\nerror: file not found\nToday: $(date)\nHostname: $(hostname)"; sleep 60; done']
  348  EOF
  349  kubectl get pod -A
  350  kubectl config use-context hk8s
  351  kubectl get deployments.apps 
  352  kubectl get deployments.apps -A
  353  kubectl get pods -A
  354  exit
  355  ssh k8s-master
  356  kubectl config use-context k8s
  357  kubectl config current-context 
  358  cat <<EOF | kubectl apply -f -
  359  ---
  360  apiVersion: v1
  361  kind: Namespace
  362  metadata:
  363    name: migops
  364    labels:
  365      team: migops
  366  ---
  367  apiVersion: v1
  368  kind: Namespace
  369  metadata:
  370    name: devops
  371    labels:
  372      team: devops
  373  ---
  374  apiVersion: v1
  375  kind: Namespace
  376  metadata:
  377    name: presales
  378    labels:
  379      team: presales
  380  ---
  381  ## namespcae customera
  382  apiVersion: v1
  383  kind: Namespace
  384  metadata:
  385    name: customera
  386    labels:
  387      partition: customera
  388  ---
  389  ## namespcae customera
  390  apiVersion: v1
  391  kind: Namespace
  392  metadata:
  393    name: customerb
  394    labels:
  395      partition: customerb
  396  ---
  397  ## namespcae app-team1
  398  apiVersion: v1
  399  kind: Namespace
  400  metadata:
  401    name: app-team1
  402  ---
  403  ## deploy and service-port ߰  ؼ  
  404  ## k8s
  405  apiVersion: apps/v1
  406  kind: Deployment
  407  metadata:
  408    name: front-end
  409  spec:
  410    selector:
  411      matchLabels:
  412        run: nginx
  413    replicas: 2
  414    template:
  415      metadata:
  416        labels:
  417          run: nginx
  418      spec:
  419        containers:
  420        - name: http
  421          image: nginx
  422  ---
  423  ## storage class        PV      غ 
  424  ##      : pvc     - pod     Ʈ - pvc size Ȯ  
  425  apiVersion: v1
  426  kind: PersistentVolume
  427  metadata:
  428    name: pv1
  429  spec:
  430    capacity:
  431      storage: 1Gi
  432    accessModes:
  433    - ReadWriteMany
  434    - ReadOnlyMany
  435    persistentVolumeReclaimPolicy: Recycle
  436    storageClassName: app-hostpath-sc
  437    hostPath:
  438      path: /data/storage
  439  ---
  440  apiVersion: v1
  441  kind: PersistentVolume
  442  metadata:
  443    name: pv2
  444  spec:
  445    capacity:
  446      storage: 1Gi
  447    accessModes:
  448    - ReadWriteMany
  449    - ReadOnlyMany
  450    persistentVolumeReclaimPolicy: Recycle
  451    storageClassName: app-data-sc
  452    hostPath:
  453      path: /data/volume
  454  ---
  455  ## sidecar container
  456  apiVersion: v1
  457  kind: Pod
  458  metadata:
  459    name: eshop-cart-app
  460  spec:
  461    containers:
  462    - image: busybox
  463      name: cart-app
  464      command: ['/bin/sh', '-c', 'i=1; while :;do  echo -e "$i: Price: $((RANDOM % 10000 + 1))" >> /var/log/cart-app.log; i=$((i+1)); sleep 2; done']
  465      volumeMounts:
  466      - name: varlog
  467        mountPath: /var/log
  468    volumes:
  469    - emptyDir: {}
  470      name: varlog
  471  ---
  472  ## rolling update
  473  ## k8s
  474  ## replicas      5     Ȯ  
  475  apiVersion: apps/v1
  476  kind: Deployment
  477  metadata:
  478    name: eshop-order
  479    namespace: devops
  480  spec:
  481    replicas: 2
  482    selector:
  483      matchLabels:
  484        name: order
  485    template:
  486      metadata:
  487        name: order
  488        labels:
  489          name: order
  490      spec:
  491        containers:
  492        - name: nginx-container
  493          image: nginx:1.14
  494  ---
  495  # NetworkPolicy
  496  kind: Pod
  497  apiVersion: v1
  498  metadata:
  499    name: web
  500    namespace: migops
  501    labels:
  502      app: webwas
  503      tier: frontend
  504  spec:
  505    containers:
  506    - name: web
  507      image: smlinux/cent-mysql:v1
  508      command: ["/bin/bash"]
  509      args: ["-c", "while true; do echo hello; sleep 10;done"]
  510  ---
  511  kind: Pod
  512  apiVersion: v1
  513  metadata:
  514    name: was
  515    namespace: migops
  516    labels:
  517      app: webwas
  518      tier: application
  519  spec:
  520    containers:
  521    - name: was
  522      image: smlinux/cent-mysql:v1
  523      command: ["/bin/bash"]
  524      args: ["-c", "while true; do echo hello; sleep 10;done"]
  525  ---
  526  kind: Pod
  527  apiVersion: v1
  528  metadata:
  529    name: db
  530    namespace: migops
  531    labels:
  532      app: webwas
  533      tier: database
  534  spec:
  535    containers:
  536      - name: db
  537        image: mysql:5.7
  538        env:
  539        - name: MYSQL_ROOT_PASSWORD
  540          value: pass
  541  ---
  542  ## init container
  543  apiVersion: v1
  544  kind: Pod
  545  metadata:
  546    name: web
  547  spec:
  548    containers:
  549    - name: nginx
  550      image: nginx
  551      command: ['sh', '-c', 'if [ ! -e "/opt/test" ];then exit;fi;']
  552      volumeMounts:
  553      - name: workdir
  554        mountPath: /opt
  555    volumes:
  556    - name: workdir
  557      emptyDir: {}
  558  ---
  559  ## log exam
  560  apiVersion: v1
  561  kind: Pod
  562  metadata:
  563    name: custom-app
  564    namespace: default
  565  spec:
  566    containers:
  567    - name: app
  568      image: busybox
  569      command: ['/bin/sh', '-c', 'while :;do echo -e "find files\nerror: file not found\nToday: $(date)\nHostname: $(hostname)"; sleep 60; done']
  570  ---
  571  ## sidecar exam
  572  apiVersion: v1
  573  kind: Pod
  574  metadata:
  575    name: cka-webserver
  576    namespace: default
  577  spec:
  578    containers:
  579    - image: nginx:1.14
  580      name: webserver
  581      volumeMounts:
  582      - mountPath: /var/log/nginx
  583        name: log
  584    volumes:
  585    - name: log
  586      emptyDir: {}
  587  ---
  588  ## cpu load :
  589  apiVersion: v1
  590  kind: Pod
  591  metadata:
  592    labels:
  593      name: overloaded-cpu
  594    name: campus-01
  595  spec:
  596    containers:
  597    - name: campus
  598      image: smlinux/vish-stress
  599      resources:
  600        limits:
  601          cpu: "0.4"
  602          memory: "300Mi"
  603        requests:
  604          cpu: "0.4"
  605          memory: "250Mi"
  606      args:
  607      - -cpus
  608      - "1"
  609      - -mem-total
  610      - "150Mi"
  611      - -mem-alloc-size
  612      - "100Mi"
  613      - -mem-alloc-sleep
  614      - "1s"
  615  ---
  616  apiVersion: v1
  617  kind: Pod
  618  metadata:
  619    labels:
  620      name: overloaded-cpu
  621    name: fast-01
  622  spec:
  623    containers:
  624    - name: fast
  625      image: smlinux/vish-stress
  626      resources:
  627        limits:
  628          cpu: "0.2"
  629          memory: "300Mi"
  630        requests:
  631          cpu: "0.2"
  632          memory: "250Mi"
  633      args:
  634      - -cpus
  635      - "1"
  636      - -mem-total
  637      - "250Mi"
  638      - -mem-alloc-size
  639      - "100Mi"
  640      - -mem-alloc-sleep
  641      - "1s"
  642  ---
  643  #multi-container
  644  apiVersion: v1
  645  kind: Pod
  646  metadata:
  647    name: busybox-sleep
  648  spec:
  649    containers:
  650    - name: busybox
  651      image: busybox
  652      command: ["/bin/sh"]
  653      args: ["-c", "while true; do sleep 1000; done"]
  654  EOF
  655  wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.7.0/deploy/static/provider/baremetal/deploy.yaml
  656  vi deploy.yaml
  657  kubectl apply -f deploy.yaml
  658  kubectl get svc -n ingress-nginx 
  659  cat <<END > ingress-application.yaml 
  660  apiVersion: apps/v1
  661  kind: Deployment
  662  metadata:
  663    namespace: ingress-nginx
  664    name: nginx
  665  spec:
  666    replicas: 1
  667    selector:
  668      matchLabels:
  669        name: nginx
  670    template:
  671      metadata:
  672        labels:
  673          name: nginx
  674      spec:
  675        containers:
  676        - image: nginx
  677          name: nginx
  678          ports:
  679          - containerPort: 80
  680  ---
  681  apiVersion: v1
  682  kind: Service
  683  metadata:
  684    namespace: ingress-nginx
  685    name: nginx
  686  spec:
  687    ports:
  688    - port: 80
  689      protocol: TCP
  690      targetPort: 80
  691    selector:
  692      name: nginx
  693  ---
  694  apiVersion: apps/v1
  695  kind: Deployment
  696  metadata:
  697    namespace: ingress-nginx
  698    name: appjs
  699  spec:
  700    replicas: 3
  701    selector:
  702      matchLabels:
  703        name: appjs
  704    template:
  705      metadata:
  706        labels:
  707          name: appjs
  708      spec:
  709        containers:
  710        - image: smlinux/appjs
  711          name: appjs
  712          ports:
  713          - containerPort: 80
  714  ---
  715  apiVersion: v1
  716  kind: Service
  717  metadata:
  718    namespace: ingress-nginx
  719    name: appjs-service
  720  spec:
  721    ports:
  722    - port: 80
  723      targetPort: 80
  724    selector:
  725      name: appjs
  726  END
  727  kubectl apply -f ingress-application.yaml
  728  etcdctl  version
  729  ssh k8s-master
  730  wget  https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
  731  vi components.yaml
  732  kubectl apply -f components.yaml
  733  kubectl get namespaces 
  734  kubectl get nodes
  735  kubectl get namespaces 
  736  kubectl get nodes
  737  kubectl get namespaces 
  738  kubectl get nodes 
  739  exit
  740  clear
  741  kubectl get nodes
  742  kubectl config use-context k8s
  743  kubectl get nodes
  744  kubectl config use-context k8s
  745  kubectl get nodes
  746  kubectl config use-context hk8s
  747  kubectl get nodes
  748  clear
  749  kubectl config use-context k8s
  750  kubectl run weblog --image=nginx:1.17 --dry-run=client -o yaml > weblog.yaml
  751  vi weblog.yaml 
  752  cat weblog.yaml 
  753  kubectl apply -f weblog.yaml 
  754  vi weblog.yaml 
  755  kubectl apply -f weblog.yaml 
  756  kubectl get pv
  757  clear
  758  kubectl describe pods weblog 
  759  kubectl get pods weblog 
  760  vi weblog.yaml 
  761  kubectl describe pods weblog 
  762  clear
  763  kubectl config use-context k8s
  764  cd /data/cka
  765  kubectl run fluentd --image=fluentd
  766  kubectl get pods
  767  clear
  768  kubectl get pods
  769  kubectl get pods -o yaml > fluentd.yaml
  770  vi fluentd.yaml 
  771  kubectl apply -f fluentd.yaml 
  772  vi fluentd.yaml 
  773  kubectl delete pods fluentd 
  774  kubectl apply -f fluentd.yaml 
  775  vi fluentd.yaml 
  776  kubectl apply -f fluentd.yaml 
  777  kubectl describe pods fluentd 
  778  :kubectl get pod -o wide
  779  :kubectl get pods fluentd -o wide
  780  :kubect get pods fluentd -o wide
  781  :kubectl get pods fluentd -o wide
  782  kubectl get pods fluentd -o wide
  783  kubectl describe pods fluentd 
  784  vi fluentd.yaml 
  785  clear
  786  kubectl config use-context hk8s
  787  cd ..
  788  cd ~
  789  vi pv.yaml
  790  kubectl apply -f pv.yaml 
  791  kubectl get pv
  792  vi pv.yaml
  793  kubectl config use-context k8s
  794  vi pvc.yaml
  795  kubectl apply -f pvc.yaml 
  796  kubectl get pvc
  797  vi pvc.yaml
  798  kubectl get pc
  799  kubectl get pv
  800  vi pvc.yaml
  801  clear
  802  vi pvc-pod.yaml
  803  kubectl apply -f pvc-pod.yaml 
  804  kubectl describe pod web-server-pod 
  805  clear
  806  kubectl config use-context k8s
  807  kubectl get deployments.apps -n devops
  808  kubectl get pods -n devops |grep eshop-order
  809  kubectl scale deployment -n devops eshop-order --replicas=5
  810  kubectl get pods -n devops |grep eshop-order
  811  clezr
  812  kubectl config use-context hk8s
  813  kubectl get pv --sort-by=.spec.capacity.storage
  814  kubectl get pv --sort-by=.spec.capacity.storage > /var/CKA2023/my-pv-list
  815  cat /var/CKA2023/my-pv-list
  816  kubectl config current-context 
  817  kubectl config use-context k8s
  818  kubectl get pv --sort-by=.spec.capacity.storage
  819  kubectl get pv --sort-by=.spec.capacity.storage > /var/CKA2023/my-pv-list
  820  cat /var/CKA2023/my-pv-list
  821  clear
  822  kubectl config use-context k8s
  823  kubectl get pods --show-labels
  824  kubectl get pods
  825  kubectl config use-context hk8s
  826  kubectl get pods
  827  kubectl get pod -A
  828  kubectl config use-context k8s
  829  kubectl get pods -A
  830  vi custom-app.yaml
  831  kubectl apply -f custom-app.yaml 
  832  kubectl get pods -A
  833  clear
  834  kubectl get pods --show-labels
  835  kubectl top pods --sort-by=cpu
  836  ehco "campus-01" > /var/CKA2023/custom-app-log 
  837  echo "campus-01" > /var/CKA2023/custom-app-log 
  838  cat /var/CKA2023/custom-app-log
  839  clear
  840  kubectl get pods --show-labels |grep name=overloaded-cpu
  841  kubectl top pods --sort-by=cpu
  842  echo "campus-01" > /var/CKA2023/custom-app-log
  843  cat /var/CKA2023/custom-app-log
  844  kubectl top pods -l name=overloaded-cpu --sort-by=cpu
  845  echo "campus-01" > /var/CKA2023/custom-app-log
  846  cat /var/CKA2023/custom-app-log
  847  kubectl get deployments.apps 
  848  kubectl get deployments.apps front-end --dry-run=client -o yaml > front.yaml
  849  clear
  850  kubectl get deployments.apps front-end --dry-run=client -o yaml > front.yaml
  851  clear
  852  kubectl config use-context k8s
  853  kubectl create deployment nginx-app --image=nginx:1.11.10-alpine --replicas=3
  854  kubectl get pods |grep nginx-app
  855  kubectl get deployments.apps nginx-app --dry-run=client -o yaml > nginx-app.yaml
  856  kubectl get deployments.apps nginx-app -o yaml > nginx-app.yaml
  857  cat nginx-app.yaml 
  858  clear
  859  kubectl set image deploy nginx-app nginx=nginx:1.11.13-alpine 
  860  kubectl get pods |grep nginx-app
  861  kubectl describe pods nginx-app-66bfd44d9d-vjldp 
  862  clear
  863  kubectl rollout history deployment nginx-app
  864  kubectl rollout undo deployment nginx-app
  865  kubectl get pods |grep nginx-app
  866  kubectl describe pods nginx-app-f77bb967-tj6g4
  867  clear
  868  kubectl config use-context hk8s
  869  kubectl get nodes
  870  ssh hk8s-worker2
  871  kubectl get nodes
  872  ssh hk8s-worker2
  873  kubectl get nodes
  874  ssh hk8s-worker2
  875  kubectl get nodes
  876  clear
  877  kubectl get nodes
  878  ssh hk8s-worker2
  879  kubectl get nodes
  880  clear
  881  kubectl config use-context hk8s
  882  ssh hk8s-master
  883  kubectl config use-context k8s
  884  clear
  885  kubectl get nodes
  886  kubectl get pods -A
  887  clear
  888  kubectl get pods -o wide -A
  889  kubectl drain k8s-worker2
  890  kubectl drain k8s-worker2 --ignore-daemonsets
  891  kubectl drain k8s-worker2 --ignore-daemonsets --force
  892  kubectl drain k8s-worker2 --ignore-daemonsets --force --delete-emptydir-data
  893  clear
  894  kubectl get nodes
  895  kubectl get pods -A
  896  kubectl get pods -o wide -A
  897  kubectl get nodes
  898  kubectl uncordon k8s-worker2
  899  kubectl get nodes
  900  kubectl get pods -o wide -A
  901  history
ubuntu@console:~$ 