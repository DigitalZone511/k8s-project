########=====eksctl 명령을 이용해서 한정원 AWS EKS 생성하기[2024년8월10일(토)] 가이드문서=====#######

==============================================================================================
1.  ubuntu22.0.4(Ubuntu Server 22.04 LTS (HVM), SSD Volume Type Linux EC2) 호스트 준비
    AWS EC2 instance를 생성해서 eks managed Server로 사용  
    우선 먼저 AWS EC2 Ubuntu20.0.4 Linux 를 하나 만들자 (어디에 : VEC-PRD-VPC-NGINX-PUB-2A 서브넷에 만들자)
==============================================================================================
2. ubuntu Linux EC2 에 AWS CLI 관리툴인 aws cli 설치 
  참고: https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/install-cliv2-linux.html
  $ sudo apt-get install -y unzip
  $ curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
  $ unzip awscliv2.zip
  $ sudo ./aws/install
	  You can now run: /usr/local/bin/
	  
  $ aws  --version
aws-cli/2.15.48 Python/3.11.8 Linux/6.5.0-1017-aws exe/x86_64.ubuntu.22 prompt/off
===============================================================================================  
3. ubuntu Linux EC2 에 EKS설치/운영 툴인  eksctl 설치
  참고: https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/eksctl.html
  $ curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
  $ sudo mv /tmp/eksctl /usr/local/bin
  $ eksctl version
0.176.0

===============================================================================================    
4.  ubuntu Linux EC2 에 k8s 관리툴인 kubectl 설치
  참고: https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/install-kubectl.html
  $ curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.21.2/2021-07-05/bin/linux/amd64/kubectl
  $ chmod +x ./kubectl
  $ mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
  $ echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
  $ kubectl version --short --client 
    Client Version: v1.21.2-13+d2965f0db10712

===============================================================================================
5.  ubuntu Linux EC2 에서 aws 관리 할수 있도록 CLI 통한  로그인 하기 
===============================================================================================
root@ip-10-250-1-234:~# aws configure
AWS Access Key ID [None]: AKIAYVHTDRPOZxxxxxxxxxx  (본인 Access Key)
AWS Secret Access Key [None]: pumZ38bnidBiL6mQ/l7B6TzlZDaxxxxxxxxxxxxx (본인 Secret Access Key)
Default region name [None]: ap-northeast-2
Default output format [None]: 
root@ip-10-250-1-234:~# 
===============================================================================
root@ip-10-250-1-234:~# aws configure list
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                <not set>             None    None
access_key     ****************RFGA shared-credentials-file    
secret_key     ****************0hbu shared-credentials-file    
    region           ap-northeast-2      config-file    ~/.aws/config
===============================================================================
root@ip-10-250-1-234:~# aws sts get-caller-identity  
{
    "UserId": "595362810xxx",
    "Account": "595362810xxx",
    "Arn": "arn:aws:iam::595362810Xxxx:root"
}
===============================================================================정상로그인 되었음

7. Ubuntu22.04 버전에 Docker 데몬을 설치하자 [전달해 드린 Docker 설치 (install-docker.sh 실행)]

8. root@ip-10-250-1-234:~# mkdir dockerfile-folder
root@ip-10-250-1-234:~# exit
logout
ubuntu@ip-10-250-1-234:~$ ls
dockerfile  index.html
ubuntu@ip-10-250-1-234:~$ sudo mv ./* /root/dockerfile-folder
ubuntu@ip-10-250-1-234:~$ su -
Password: 
root@ip-10-250-1-234:~# ls
aws  awscliv2.zip  bin  dockerfile-folder  kubectl  snap
root@ip-10-250-1-234:~# cd dockerfile-folder/
root@ip-10-250-1-234:~/dockerfile-folder# ls
dockerfile  index.html
root@ip-10-250-1-234:~/dockerfile-folder# vi dockerfile 
root@ip-10-250-1-234:~/dockerfile-folder# ls
dockerfile  index.html
root@ip-10-250-1-234:~/dockerfile-folder# docker build -t eks-nginx .

root@ip-10-250-1-234:~/dockerfile-folder# docker images
REPOSITORY   TAG       IMAGE ID       CREATED         SIZE
ecs-nginx    latest    1eea60601fcb   6 seconds ago   187MB
root@ip-10-250-1-234:~/dockerfile-folder# docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
root@ip-10-250-1-234:~/dockerfile-folder# docker run -d --name nginx-container -p 8000:80 1eea60601fcb
e2d4dd16846ed7429db50dc586f6bc3b335488a1e06f75f02b74b367564a714b
root@ip-10-250-1-234:~/dockerfile-folder# docker ps
CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                                   NAMES
e2d4dd16846e   1eea60601fcb   "/docker-entrypoint.…"   4 seconds ago   Up 2 seconds   0.0.0.0:8000->80/tcp, :::8000->80/tcp   nginx-container
root@ip-10-250-1-234:~/dockerfile-folder# curl http://43.203.195.200:8000
<html>
<head> 
<title>Amazon EKS Connected Success !!!</title> 
<style>
body {margin-top: 40px; background-color: #333;}
</style> 
</head>
<body>
<div style=color:white;text-align:center>
<h1>Amazon EKS Connected Success !!!</h1>
<h2>Congratulations!</h2>
<p><em>Your application is now running on a container in Amazon EKS.</em></p>
</p> </div>
</body>
</html>root@ip-10-250-1-234:~/dockerfile-folder# 

9.  정상적으로 "Amazon EKS Connected Success !!!" 뜬다면 다음은 AWS ECR에 기존 빌드했던 컨테이너 이미지를 등록 해보자 

9-1 아래명령어 실행 (AWS ECR 푸쉬명령어보기 화면 선택후 1번명령어를 복사해 온다)
root@ip-10-250-1-234:~/dockerfile-folder# aws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin 595362810845.dkr.ecr.ap-northeast-2.amazonaws.com
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded

9-2 컨테이너 빌드는 진행 완료 했으므로 생략한다.
9-3 아래명령어 실행
root@ip-10-250-1-234:~/dockerfile-folder# docker tag eks-nginx:latest 5953628108XX.dkr.ecr.ap-northeast-2.amazonaws.com/eks-nginx:latest

9-4 아래명령어 실행
root@ip-10-250-1-234:~/dockerfile-folder# docker push 5953628108XX.dkr.ecr.ap-northeast-2.amazonaws.com/eks-nginx:latest
The push refers to repository [5953628108XX.dkr.ecr.ap-northeast-2.amazonaws.com/ecs-nginx]
48f9f816312a: Pushed 
009507b85609: Pushed 
fbcc9bc44d3e: Pushed 
b4ad47845036: Pushed 
eddcd06e5ef9: Pushed 
b61d4b2cd2da: Pushed 
b6c2a8d6f0ac: Pushed 
571ade696b26: Pushed 
latest: digest: sha256:c201620f18943f342eb98e8a3edd0ec61f506b63b2bb4751751937ef2079c8f0 size: 1985
root@ip-10-250-1-234:~/dockerfile-folder# 

위와 같이 정상적으로 AWS ECR에 컨테이너 이미지가 올라가는것을 볼 수 있다.
======================================================================================================
10. 본격으로 EKS 구성해 보자 
  참고: https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/getting-started-eksctl.html
 =====================================================================================================
 0. First, create cluster.yaml file:  vi cluster.yaml 빈 yaml 파일을 생성한다.  단 주의할점은 여러분의 환경에 맞도록 subnet 을 수정한다.
 1. 아래 yaml 파일을 복사하여 붙여 놓는다.
 2. eksctl create cluster -f cluster.yaml  실행한다.
 3. eksctl delete cluster -f cluster.yaml  삭제한다.
======================================================================================================
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: powermvp-cluster
  region:  ap-northeast-2
vpc:
  subnets:
    private:
      ap-northeast-2a: { id: subnet-0d8ba4e71c5efdac5 }
      ap-northeast-2c: { id: subnet-09c2a00cd2c88eb04 }

nodeGroups:
  - name: VEC-PRD-NG-worker1
    labels: { role: workers }
    instanceType: t3.medium
    desiredCapacity: 1
    privateNetworking: true
    subnets:
      - subnet-0d8ba4e71c5efdac5
  - name: VEC-PRD-NG-worker2
    labels: { role: workers }
    instanceType: t3.medium
    desiredCapacity: 1
    privateNetworking: true
    subnets:
      - subnet-09c2a00cd2c88eb04
    iam:
      withAddonPolicies:
        imageBuilder: true

====================================================================================
   CloudFormation으로 생성되기 때문에 aws에서 cloudformation으로 확인해본다.
   생성되는 시간이 20분정도 걸린다.
	...
	2024-05-04 14:02:26 [ℹ]  eksctl version 0.176.0
2024-05-04 14:02:26 [ℹ]  using region ap-northeast-2
2024-05-04 14:02:26 [✔]  using existing VPC (vpc-011c8dbcc4bc0f1e5) and subnets (private:map[ap-northeast-2a:{subnet-0d8ba4e71c5efdac5 ap-northeast-2a 10.250.2.0/24 0 } ap-northeast-2c:{subnet-09c2a00cd2c88eb04 ap-northeast-2c 10.250.12.0/24 0 }] public:map[])
2024-05-04 14:02:26 [!]  custom VPC/subnets will be used; if resulting cluster doesn't function as expected, make sure to review the configuration of VPC/subnets
2024-05-04 14:02:26 [ℹ]  nodegroup "VEC-PRD-NG-worker1" will use "ami-003abae84f9294f2b" [AmazonLinux2/1.29]
2024-05-04 14:02:26 [ℹ]  nodegroup "VEC-PRD-NG-worker2" will use "ami-003abae84f9294f2b" [AmazonLinux2/1.29]
2024-05-04 14:02:26 [ℹ]  using Kubernetes version 1.29
2024-05-04 14:02:26 [ℹ]  creating EKS cluster "powermvp-cluster" in "ap-northeast-2" region with un-managed nodes
2024-05-04 14:02:26 [ℹ]  2 nodegroups (VEC-PRD-NG-worker1, VEC-PRD-NG-worker2) were included (based on the include/exclude rules)
2024-05-04 14:02:26 [ℹ]  will create a CloudFormation stack for cluster itself and 2 nodegroup stack(s)
2024-05-04 14:02:26 [ℹ]  will create a CloudFormation stack for cluster itself and 0 managed nodegroup stack(s)
2024-05-04 14:02:26 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=ap-northeast-2 --cluster=powermvp-cluster'
2024-05-04 14:02:26 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "powermvp-cluster" in "ap-northeast-2"
2024-05-04 14:02:26 [ℹ]  CloudWatch logging will not be enabled for cluster "powermvp-cluster" in "ap-northeast-2"
2024-05-04 14:02:26 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=ap-northeast-2 --cluster=powermvp-cluster'
2024-05-04 14:02:26 [ℹ]  
2 sequential tasks: { create cluster control plane "powermvp-cluster", 
    2 sequential sub-tasks: { 
        wait for control plane to become ready,
        2 parallel sub-tasks: { 
            create nodegroup "VEC-PRD-NG-worker1",
            create nodegroup "VEC-PRD-NG-worker2",

2024-05-04 14:12:28 [ℹ]  deploying stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker1"
2024-05-04 14:12:28 [ℹ]  deploying stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker2"
2024-05-04 14:12:28 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker1"
2024-05-04 14:12:28 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker2"
2024-05-04 14:12:58 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker1"
2024-05-04 14:12:58 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker2"
2024-05-04 14:13:32 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker1"
2024-05-04 14:13:49 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker2"
2024-05-04 14:14:23 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker2"
2024-05-04 14:14:47 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker1"
2024-05-04 14:15:21 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker1"
2024-05-04 14:15:39 [ℹ]  waiting for CloudFormation stack "eksctl-powermvp-cluster-nodegroup-VEC-PRD-NG-worker2"
2024-05-04 14:15:39 [ℹ]  waiting for the control plane to become ready
2024-05-04 14:15:39 [✔]  saved kubeconfig as "/home/ubuntu/.kube/config"
2024-05-04 14:15:39 [ℹ]  no tasks
2024-05-04 14:15:39 [✔]  all EKS cluster resources for "powermvp-cluster" have been created
2024-05-04 14:15:39 [ℹ]  nodegroup "VEC-PRD-NG-worker1" has 1 node(s)
2024-05-04 14:15:39 [ℹ]  node "ip-10-250-2-114.ap-northeast-2.compute.internal" is ready
2024-05-04 14:15:39 [ℹ]  waiting for at least 1 node(s) to become ready in "VEC-PRD-NG-worker1"
2024-05-04 14:15:39 [ℹ]  nodegroup "VEC-PRD-NG-worker1" has 1 node(s)
2024-05-04 14:15:39 [ℹ]  node "ip-10-250-2-114.ap-northeast-2.compute.internal" is ready
2024-05-04 14:15:39 [ℹ]  nodegroup "VEC-PRD-NG-worker2" has 1 node(s)
2024-05-04 14:15:39 [ℹ]  node "ip-10-250-12-197.ap-northeast-2.compute.internal" is ready
2024-05-04 14:15:39 [ℹ]  waiting for at least 1 node(s) to become ready in "VEC-PRD-NG-worker2"
2024-05-04 14:15:39 [ℹ]  nodegroup "VEC-PRD-NG-worker2" has 1 node(s)
2024-05-04 14:15:39 [ℹ]  node "ip-10-250-12-197.ap-northeast-2.compute.internal" is ready
2024-05-04 14:15:39 [✔]  created 2 nodegroup(s) in cluster "powermvp-cluster"
2024-05-04 14:15:39 [✔]  created 0 managed nodegroup(s) in cluster "powermvp-cluster"
2024-05-04 14:15:40 [ℹ]  kubectl command should work with "/home/ubuntu/.kube/config", try 'kubectl get nodes'
2024-05-04 14:15:40 [✔]  EKS cluster "powermvp-cluster" in "ap-northeast-2" region is ready


	- aws에서 확인 :  CloudFormation 검색 후 확인
 =================================================================================
11.  CLI 명령어 자동완성 기능을 추가 한후 , 다음과 같이 설치 결과 확인하자.

CLI 명령어 완성기능 추가
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc
=================================================================================
12. 클러스터 이동 명령어 
aws eks --region ap-northeast-2 update-kubeconfig --name powermvp-cluster
aws eks --region ap-northeast-2 update-kubeconfig --name console-cluster
aws eks --region ap-northeast-2 update-kubeconfig --name console-cluster2

13. kubectl 명령으로 설치결과 확인
$ kubectl get nodes
NAME                                                STATUS   ROLES    AGE   VERSION
ip-192-168-38-198.ap-northeast-2.compute.internal   Ready    <none>   28m   v1.19.6-eks-49a6c0
ip-192-168-4-22.ap-northeast-2.compute.internal     Ready    <none>  28m    v1.19.6-eks-49a6c0
ip-192-168-82-229.ap-northeast-2.compute.internal   Ready    <none>   28m   v1.19.6-eks-49a6c0

root@ip-10-250-1-234:~/dockerfile-folder# kubectl get pods -A
NAMESPACE     NAME                        READY   STATUS    RESTARTS   AGE
default       webserver-b64b4cd9f-4xqcb   1/1     Running   0          9m16s
default       webserver-b64b4cd9f-d88dp   1/1     Running   0          9m16s
default       webserver-b64b4cd9f-hbqb5   1/1     Running   0          9m16s
default       webserver-b64b4cd9f-nmvqq   1/1     Running   0          9m16s
default       webserver-b64b4cd9f-zms62   1/1     Running   0          9m16s
kube-system   aws-node-fkg4q              2/2     Running   0          56m
kube-system   aws-node-r7jd7              2/2     Running   0          56m
kube-system   coredns-6b46bd4fd9-2pkhw    1/1     Running   0          63m
kube-system   coredns-6b46bd4fd9-5rvzq    1/1     Running   0          63m
kube-system   kube-proxy-476l7            1/1     Running   0          56m
kube-system   kube-proxy-b8xlr            1/1     Running   0          56m

root@ip-10-250-1-234:~/dockerfile-folder# kubectl get pods --all-namespaces (자체 구축한 kubernetes cluster 차이점이 존재한다.)
NAMESPACE     NAME                        READY   STATUS    RESTARTS   AGE
default       webserver-b64b4cd9f-4xqcb   1/1     Running   0          11m
default       webserver-b64b4cd9f-d88dp   1/1     Running   0          11m
default       webserver-b64b4cd9f-hbqb5   1/1     Running   0          11m
default       webserver-b64b4cd9f-nmvqq   1/1     Running   0          11m
default       webserver-b64b4cd9f-zms62   1/1     Running   0          11m
kube-system   aws-node-fkg4q              2/2     Running   0          59m
kube-system   aws-node-r7jd7              2/2     Running   0          58m
kube-system   coredns-6b46bd4fd9-2pkhw    1/1     Running   0          65m
kube-system   coredns-6b46bd4fd9-5rvzq    1/1     Running   0          65m
kube-system   kube-proxy-476l7            1/1     Running   0          58m
kube-system   kube-proxy-b8xlr            1/1     Running   0          59m

=============================================================================(자체 구축한 kubernetes cluster 차이점이 존재한다.)
root@master:~# kubectl get pods --all-namespaces 
NAMESPACE     NAME                                         READY   STATUS    RESTARTS        AGE
kube-system   coredns-64897985d-f5glr                      1/1     Running   10 (130m ago)   11d
kube-system   coredns-64897985d-jqdrg                      1/1     Running   10 (130m ago)   11d
kube-system   etcd-master.example.com                      1/1     Running   12 (130m ago)   11d
kube-system   kube-apiserver-master.example.com            1/1     Running   12 (130m ago)   11d
kube-system   kube-controller-manager-master.example.com   1/1     Running   25 (130m ago)   11d
kube-system   kube-proxy-4nmw6                             1/1     Running   10 (129m ago)   10d
kube-system   kube-proxy-brhcf                             1/1     Running   13 (129m ago)   11d
kube-system   kube-proxy-gf5wj                             1/1     Running   12              11d
kube-system   kube-proxy-xqxql                             1/1     Running   12 (128m ago)   11d
kube-system   kube-scheduler-master.example.com            1/1     Running   25 (130m ago)   11d
kube-system   metrics-server-6f9c74757-ckk2t               1/1     Running   3 (128m ago)    2d23h
kube-system   weave-net-krk4t                              2/2     Running   22 (129m ago)   10d
kube-system   weave-net-m6k9m                              2/2     Running   28 (129m ago)   11d
kube-system   weave-net-pcrxn                              2/2     Running   28 (128m ago)   11d
kube-system   weave-net-xfvl5                              2/2     Running   32 (130m ago)   11

=============================================================================================================
14. 간단한 실행 실습
워커 노드 정보 보기
$ kubectl get nodes -o wide

Pod 배포 TEST. nginx 컨테이너 5개 실행하고 결과 확인
$ kubectl create  deployment webserver --image=nginx:1.14 --port=80  --replicas=5
$ kubectl get  pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE   IP               NODE                                               NOMINATED NODE   READINESS GATES
webtest-fdf54587f-8mfrz   1/1      Running   0          28s   192.168.10.139   ip-192-168-2-91.ap-northeast-2.compute.internal    <none>           <none>
webtest-fdf54587f-d4pjc   1/1      Running   0          28s   192.168.39.104   ip-192-168-56-22.ap-northeast-2.compute.internal   <none>           <none>
webtest-fdf54587f-dqg55   1/1      Running   0          28s   192.168.13.27    ip-192-168-2-91.ap-northeast-2.compute.internal    <none>           <none>
webtest-fdf54587f-hs8zd   1/1      Running   0          28s   192.168.77.185   ip-192-168-70-30.ap-northeast-2.compute.internal   <none>           <none>
webtest-fdf54587f-pn549   1/1      Running   0          28s   192.168.83.249   ip-192-168-70-30.ap-northeast-2.compute.internal   <none>           <none>

다른 EKS ClUSTER 접속하기 위해서는 아래와 같이 명령어 실행
root@ip-10-250-1-234:~/dockerfile-folder# aws eks --region ap-northeast-2 update-kubeconfig --name eks-cluster
Added new context arn:aws:eks:ap-northeast-2:595362810845:cluster/eks-cluster to /root/.kube/config
root@ip-10-250-1-234:~/dockerfile-folder# kubectl get nodes
NAME                                               STATUS   ROLES    AGE     VERSION
ip-10-250-12-195.ap-northeast-2.compute.internal   Ready    <none>   6m39s   v1.28.5-eks-5e0fdde
ip-10-250-2-251.ap-northeast-2.compute.internal    Ready    <none>   6m41s   v1.28.5-eks-5e0fdde
root@ip-10-250-1-234:~/dockerfile-folder# kubectl get pods --all-namespaces 
NAMESPACE     NAME                           READY   STATUS    RESTARTS   AGE
kube-system   aws-node-ppdkl                 2/2     Running   0          2m54s
kube-system   aws-node-w9jm2                 2/2     Running   0          2m58s
kube-system   coredns-56dfff779f-hclqn       1/1     Running   0          11m
kube-system   coredns-56dfff779f-nkpnq       1/1     Running   0          11m
kube-system   eks-pod-identity-agent-725kv   1/1     Running   0          2m59s
kube-system   eks-pod-identity-agent-fn9j6   1/1     Running   0          2m59s
kube-system   kube-proxy-5jhhv               1/1     Running   0          6m54s
kube-system   kube-proxy-sn4k7               1/1     Running   0          6m56s

===============================================================================================================
15. nginx 웹서버에 클라이언트 접속 가능하도록 구성하고 간단히 TEST
$ kubectl expose deployment  webserver --port=80 --type=LoadBalancer
ubuntu@ip-10-250-1-198:~$ kubectl get svc
NAME         TYPE           CLUSTER-IP       EXTERNAL-IP                                                                    PORT(S)        AGE
kubernetes   ClusterIP      172.20.0.1       <none>                                                                         443/TCP        13m
webserver    LoadBalancer   172.20.100.109   aa98c206c61d44dcaab7669d388630e1-2052664679.ap-northeast-2.elb.amazonaws.com   80:30948/TCP   9s

1분정도 후에 웹브라우저를 통해 웹서버 연결되는지 확인  (nginx 홈페이지가 떠야 한다.)
http://aa98c206c61d44dcaab7669d388630e1-2052664679.ap-northeast-2.elb.amazonaws.com

16. 모든 실습이 끝났고, 더이상 EKS 사용하지 않는다면 아래 명령으로 삭제. 삭제하지 않고 두면???? 음.. 나중에 깜딱 놀랄수도 있어요~ EKS, EC2 모두 과금됩니다.
    삭제시 반드시 Cloud Formation 스텍에서도 삭제를 시켜주는 것이 좋다.
$ eksctl delete cluster --name vec-powermvp
2021-05-21 18:39:08 [ℹ]  eksctl version 0.50.0
2021-05-21 18:39:08 [ℹ]  using region ap-northeast-2
2021-05-21 18:39:08 [ℹ]  deleting EKS cluster "k8s-demo"
2021-05-21 18:39:08 [ℹ]  deleted 0 Fargate profile(s)
2021-05-21 18:39:09 [✔]  kubeconfig has been updated
2021-05-21 18:39:09 [ℹ]  cleaning up AWS load balancers created by Kubernetes objects of Kind Service or Ingress
...
2021-05-21 18:42:37 [ℹ]  waiting for CloudFormation stack "eksctl-k8s-demo-addon-iamserviceaccount-kube-system-aws-node"
2021-05-21 18:42:55 [ℹ]  waiting for CloudFormation stack "eksctl-k8s-demo-addon-iamserviceaccount-kube-system-aws-node"
2021-05-21 18:42:55 [ℹ]  deleted serviceaccount "kube-system/aws-node"
2021-05-21 18:42:56 [ℹ]  will delete stack "eksctl-k8s-demo-cluster"
2021-05-21 18:42:56 [✔]  all cluster resources were deleted
지우는 시간도 오래 걸려요~

[실습]==================================================================================
우리가 올린 AWS ECR 컨테이너 이미지를 deploy 통해 배포를 진행해 보자
vi deploy-nginx.yaml 
kubectl apply -f deploy-nginx.yaml
==================================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webui
spec:
  replicas: 4
  selector:
    matchLabels:
      app: webui
  template:
    metadata:
      name: nginx-pod
      labels:
        app: webui
    spec:
      containers:
      - name: nginx-container
        image: 595362810845.dkr.ecr.ap-northeast-2.amazonaws.com/ecs-nginx
      tolerations:
      - key: "role"
        operator: "Equal"
        value: "web"
        effect: "NoSchedule"
======================================================================================
root@ip-10-250-1-234:~/dockerfile-folder# kubectl get pods
NAME                     READY   STATUS              RESTARTS   AGE
webui-58dfd98b65-ffscv   1/1     Running             0          5s
webui-58dfd98b65-jdr7t   1/1     Running             0          5s
webui-58dfd98b65-l89dk   0/1     ContainerCreating   0          5s
webui-58dfd98b65-ngk7b   0/1     ContainerCreating   0          5s
root@ip-10-250-1-234:~/dockerfile-folder# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
webui-58dfd98b65-ffscv   1/1     Running   0          16s
webui-58dfd98b65-jdr7t   1/1     Running   0          16s
webui-58dfd98b65-l89dk   1/1     Running   0          16s
webui-58dfd98b65-ngk7b   1/1     Running   0          16s
root@ip-10-250-1-234:~/dockerfile-folder# kubectl get deployments.apps 
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
webui   4/4     4            4           46s
root@ip-10-250-1-234:~/dockerfile-folder# kubectl expose deployment webui --port=80 --type=LoadBalancer
service/webui exposed
root@ip-10-250-1-234:~/dockerfile-folder# kubectl get svc
NAME         TYPE           CLUSTER-IP     EXTERNAL-IP                                                                    PORT(S)        AGE
kubernetes   ClusterIP      172.20.0.1     <none>                                                                         443/TCP        19m
webui        LoadBalancer   172.20.69.70   a12dd06991859437c8d90d54fd287210-1091956090.ap-northeast-2.elb.amazonaws.com   80:30498/TCP   6s

신규로 배포한 컨테이너가 브라우저 화면에 입력시 ---> http://a12dd06991859437c8d90d54fd287210-1091956090.ap-northeast-2.elb.amazonaws.com  
떠야한다.


